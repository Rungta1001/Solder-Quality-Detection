{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from math import gcd\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/dnyanada/Dropbox/data/'\n",
    "infile = 'DSC_0630.JPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.0\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(data_path+infile)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "(thresh, output) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "print(thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Background removal\n",
    "#REFERENCE: https://stackoverflow.com/questions/48395434/how-to-crop-or-remove-white-background-from-an-image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "th, threshed = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "#### (2) Morph-op to remove noise\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "#### (3) Find the max-area contour\n",
    "cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
    "\n",
    "#### (4) Crop and save it\n",
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "dst = image[y:y+h, x:x+w]\n",
    "cv2.imwrite(data_path+infile[:-4]+'_noBg.JPG', dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = cv2.imread(data_path+infile[:-4]+'_noBg.JPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "#Width and height are inverted\n",
    "factor = 4 #FIGURE OUT HOW TO FIND THIS \n",
    "width = image.shape[1]\n",
    "height = image.shape[0]\n",
    "crop_height = height//(gcd(width,height)//factor)\n",
    "crop_width = width//(gcd(width,height)//factor)\n",
    "print(gcd(width,height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 64, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped = image[:crop_height,:crop_width]\n",
    "cropped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "#cv2.imwrite(data_path+'cropped_0630.JPG',cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['mkdir', '../data/DSC_0630'], returncode=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"mkdir\", data_path+infile[:-4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_path = data_path+'DSC_0630/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_squares = gcd(width,height)//factor\n",
    "grid_count = 0\n",
    "offset = 0\n",
    "offset_list = []\n",
    "offset_list.append(offset)\n",
    "#i*crop_height and range(num_squares)\n",
    "for i in range(crop_height):\n",
    "    for j in range(crop_width):\n",
    "        cropped = image[i*num_squares:(i+1)*num_squares, j*num_squares:(j+1)*num_squares]\n",
    "        cv2.imwrite(crop_path+infile[:-4]+'_' + 'offset'+str(offset)+'_'+str(grid_count)+'.JPG', cropped)\n",
    "        grid_count += 1\n",
    "\n",
    "#Offset gridding\n",
    "grid_count = 0\n",
    "offset = num_squares//2\n",
    "offset_list.append(offset)\n",
    "#i*crop_height and range(num_squares)\n",
    "for i in range(crop_height):\n",
    "    for j in range(crop_width):\n",
    "        cropped = image[i*num_squares+offset:(i+1)*num_squares+offset, j*num_squares+offset:(j+1)*num_squares+offset]\n",
    "        cv2.imwrite(crop_path+infile[:-4]+'_' + 'offset'+str(offset)+'_'+str(grid_count)+'.JPG', cropped)\n",
    "        grid_count += 1\n",
    "        \n",
    "total_images = crop_width*crop_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = '.JPG'\n",
    "prefix = crop_path+infile[:-(len(ext))]+\"_offset\"\n",
    "#NAMING FORMAT: prefix+offset+'_'+gridcount+ext\n",
    "test = [254,284,274,293,322,429,504]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to black and white using Otsu's algorithm\n",
    "#Reference: https://stackoverflow.com/questions/7624765/converting-an-opencv-image-to-black-and-white\n",
    "\n",
    "for i in test:\n",
    "    name = prefix+'0'+'_'+str(i)\n",
    "    original = cv2.imread(name+ext, 0)\n",
    "    (thresh, output) = cv2.threshold(original, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    cv2.imwrite(name+'.bw'+ext, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#Single image test\n",
    "#The problem with Otsu threshold on sub-image: Takes intensities relatively, might accidentally assign a white color to some random spot in the centre of the image\n",
    "#Try using thresholding on the entire image and use that threshold value for subimages.\n",
    "name = prefix+'0'+'_'+str(340)\n",
    "original = cv2.imread(name+ext, 0)\n",
    "output = cv2.threshold(original, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "cv2.imwrite(name+'.bw'+ext, output)\n",
    "bw = cv2.imread(name+'.bw'+ext,0)\n",
    "print(bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm for background detection\n",
    "#Count number of white pixels in each boundary as you move inwards and set some threshold for acceptance\n",
    "#using the image rotation algorithm to count white pixels\n",
    "def accepted(bw):\n",
    "    n = bw.shape[0]\n",
    "    layer_count = []\n",
    "    for layer in range(0,n//2):\n",
    "        sum =0\n",
    "        for i in range(layer, n-layer-1):\n",
    "            last = n-layer-1\n",
    "            sum += bw[layer][i] + bw[i][last] + bw[last][n-i-1] + bw[n-i-1][layer]\n",
    "        layer_count.append(sum/255)\n",
    "        print(\"Layer : {0}, Sum : {1}\".format(layer, sum/255))\n",
    "    #Control parameters\n",
    "    backgr_thresh = 10\n",
    "    upper_layers = 4\n",
    "    #No solder case\n",
    "    if sum(layer_count)/len(layer_count) < 1:\n",
    "        return False\n",
    "    #Middle\n",
    "    elif sum(layer_count[:upper_layers])/upper_layers < backgr_thresh:\n",
    "        return True\n",
    "    #Border\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "accepted_images = []\n",
    "#for i in range(0,offset)\n",
    "#   for j in range(count_images):\n",
    "#       fetch_image <- read(path)\n",
    "#       if accepted:\n",
    "#            accepted_images.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enhance contrast of color image\n",
    "#Reference : https://chrisalbon.com/machine_learning/preprocessing_images/enhance_contrast_of_color_image/\n",
    "#Reference: https://docs.opencv.org/2.4/doc/tutorials/imgproc/histograms/histogram_equalization/histogram_equalization.html\n",
    "\n",
    "# Histogram equalization: stretched distribution, \n",
    "#i.e. most of the pixel values are concentrated around the average.\n",
    "#Stretching => make some light pixels lighter and dark pixels darker :. contrast improves\n",
    "#For color, we convert to YUV cause it helps change intensity without affecting color much\n",
    "for i in test:\n",
    "    name = prefix+'0_'+str(i)\n",
    "    original = cv2.imread(name+ext)\n",
    "    #Denoising before contrasting - using default values, refer docs\n",
    "    denoise = cv2.fastNlMeansDenoisingColored(original, None, 2,2,7,21)\n",
    "    cv2.imwrite(name+'.denoise'+ext, denoise)\n",
    "    \n",
    "    #Adds contrast\n",
    "    #TODO : find a better way, this adds too much contrast\n",
    "    image_yuv = cv2.cvtColor(denoise, cv2.COLOR_BGR2YUV)\n",
    "    image_yuv[:, :, 0] = cv2.equalizeHist(image_yuv[:, :, 0])\n",
    "    image_rgb = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2BGR)\n",
    "    cv2.imwrite(name+'.contr'+ext, image_rgb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the test files\n",
    "import glob\n",
    "import os\n",
    "for file in glob.glob(os.path.join(crop_path, \"*.gray.JPG\")):\n",
    "    os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = data_path+'text.JPG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = pytesseract.image_to_string(Image.open(infile))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
